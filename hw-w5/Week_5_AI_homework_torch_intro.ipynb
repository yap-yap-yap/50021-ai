{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Week 5 - AI homework - torch intro",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUbEmuvZJxlI"
      },
      "source": [
        "# PyTorch - homework 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efS07mO7J6AR"
      },
      "source": [
        "Please run the whole notebook with your code and submit the `.ipynb` file that includes your answers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJpzFaX0J6Zz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b301bcb5-34f5-4b9e-c06c-100ce2afe56b"
      },
      "source": [
        "from termcolor import colored\n",
        "\n",
        "student_number=\"1004570\"\n",
        "student_name=\"Zhihan Yap\"\n",
        "\n",
        "print(colored(\"Homework by \"  + student_name + ', number: ' + student_number,'red'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mHomework by Zhihan Yap, number: 1004570\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xDkwBg8LKQ_"
      },
      "source": [
        " ## Question 1 -- matrix multiplication\n",
        "\n",
        "Implement the following mathematical operation on both the CPU and GPU (use Google Colab or another cloud service if you don't have a GPU in your computer). Print:\n",
        "\n",
        "a) which type of GPU card you have and \n",
        "\n",
        "b) show the computation time for both CPU and GPU (using PyTorch). \n",
        "\n",
        "c) How much % faster is the GPU? \n",
        "\n",
        " The operation to implement is the dot product $C = B * A^T$\n",
        "\n",
        " whereby $A$ is a random matrix of size $20,000 \\times 1,000$ and $B$ is a random matrix of size $2,000 \\times 1,000$. In addition to the required information asked above:\n",
        " \n",
        " d) please also print the resulting two $C$ matrices (they should be the same btw). \n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BINvhm-PLKak"
      },
      "source": [
        "# implement solution here\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "A_t = torch.rand(1000, 20000)\n",
        "B = torch.rand(2000, 1000)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CPU\n",
        "\n",
        "start_time = time.monotonic()\n",
        "\n",
        "C = B @ A_t\n",
        "\n",
        "end_time = time.monotonic()\n",
        "\n",
        "print(C)\n",
        "print(f\"CPU: time elapsed = {end_time - start_time}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtc-VG5XN1mU",
        "outputId": "e9e226a4-82e3-4ad5-fcae-625d7d011278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[260.2056, 246.7230, 252.6091,  ..., 254.3226, 249.2874, 248.9626],\n",
            "        [259.4456, 242.5540, 252.3417,  ..., 250.8234, 256.4850, 249.8223],\n",
            "        [253.2127, 239.0423, 241.5245,  ..., 247.8385, 248.0563, 249.0806],\n",
            "        ...,\n",
            "        [255.0454, 244.5129, 240.5248,  ..., 247.6823, 252.1554, 246.8359],\n",
            "        [257.3079, 248.2373, 254.8701,  ..., 254.1974, 257.1751, 258.9467],\n",
            "        [258.8436, 245.8529, 249.1706,  ..., 246.5582, 248.1608, 249.1446]])\n",
            "CPU: time elapsed = 0.985332881999966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU\n",
        "if torch.cuda.is_available():\n",
        "  print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
        "\n",
        "  A_t_gpu = A_t.cuda()\n",
        "  B_gpu = B.cuda()\n",
        "\n",
        "  start_time = time.monotonic()\n",
        "\n",
        "  C_gpu = B @ A_t \n",
        "\n",
        "  end_time = time.monotonic()\n",
        "\n",
        "  print(C_gpu)\n",
        "  print(f\"GPU: time elapsed = {end_time - start_time}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbPB9vjBOyNy",
        "outputId": "5c79a16b-f585-4a1b-e666-8a1b6890040f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: Tesla T4\n",
            "tensor([[260.2056, 246.7230, 252.6091,  ..., 254.3226, 249.2874, 248.9626],\n",
            "        [259.4456, 242.5540, 252.3417,  ..., 250.8234, 256.4850, 249.8223],\n",
            "        [253.2127, 239.0423, 241.5245,  ..., 247.8385, 248.0563, 249.0806],\n",
            "        ...,\n",
            "        [255.0454, 244.5129, 240.5248,  ..., 247.6823, 252.1554, 246.8359],\n",
            "        [257.3079, 248.2373, 254.8701,  ..., 254.1974, 257.1751, 258.9467],\n",
            "        [258.8436, 245.8529, 249.1706,  ..., 246.5582, 248.1608, 249.1446]])\n",
            "GPU: time elapsed = 1.0105033419999927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZJXmfT-yU3g"
      },
      "source": [
        "## Question 2 - grad\n",
        "\n",
        "\n",
        "Find the gradient (partial derivatives) of the function $g(w)$ below. \n",
        "\n",
        "Let  $w=[w_1,w_2]^T$\n",
        "\n",
        "Consider  $g(w)=2w_1w_2+w_2cos(w_1)$\n",
        "\n",
        "a) In PyTorch, compute:   $\\nabla g(w)$ \n",
        "\n",
        " and verify that $\\nabla g([\\pi,1])=[2,2\\piâˆ’1]^T$ using the grad function, whereby the first position is the partial for $w_1$ and the second position is the partial for $w_2$. \n",
        "\n",
        "b) You can also write a function to manually calculate these partial derivatives! You can review your differential equations math at [here](https://www.wolframalpha.com/input/?i=derivative+y+cos%28x%29) and implement this as a second function below to verify that it comes to the same solution. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLjz6_LKt4sc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a3feb80-16ee-4a92-d7de-31805aa5b7a8"
      },
      "source": [
        "# write your solution here\n",
        "import torch\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "def g(w_t):\n",
        "  out = 2*w_t[0]*w_t[1] + w_t[1]*math.cos(w_t[0])\n",
        "  return out\n",
        "\n",
        "w = torch.tensor([math.pi, 1.0], requires_grad=True)\n",
        "g_out = g(w)\n",
        "g_out.sum().backward()\n",
        "print(w.grad == torch.tensor([2, 2*math.pi-1]))\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([True, True])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def g_grad(w1, w2):\n",
        "  w_1_grad = 2*w2 - w2*math.sin(w1)\n",
        "  w_2_grad = 2*w1 + math.cos(w1)\n",
        "  return [w_1_grad, w_2_grad]\n",
        "\n",
        "print(torch.tensor(g_grad(math.pi, 1.0)))\n",
        "print(w.grad == torch.tensor(g_grad(math.pi, 1.0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkMCnlfKZvV4",
        "outputId": "947ea2de-58da-43f3-cade-66d4a012c6a3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.0000, 5.2832])\n",
            "tensor([True, True])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJwP6ur8LKjD"
      },
      "source": [
        "## Question 3 - dance hit song prediction\n",
        "\n",
        "Implement logistic regression in PyTorch for the following dance hit song prediction training dataset: \n",
        "https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030training.csv\n",
        "\n",
        " * Input variables: a number of audio features (most already standardized so don't worry about that)\n",
        " * Target variable: Topclass1030: \n",
        "   * 1 means it was a top 10 hit song; \n",
        "   * 0 means it never went above top 30 position.\n",
        "\n",
        "This dataset is derived from my paper on dance hit song prediction, for full description of features have a look at https://arxiv.org/abs/1905.08076. \n",
        "\n",
        "Print the evolution of the loss every few epochs and train the model until it converges. \n",
        " \n",
        " After training the logistic regression model, calculate the prediction accuracy on the test set: \n",
        " https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030test.csv\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyRP6bl8t4Wc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00ee166b-56ae-402c-c41f-88c36499d5a4"
      },
      "source": [
        "# Your code here\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import numpy as np\n",
        "# load data\n",
        "!wget https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030training.csv\n",
        "\n",
        "data = pd.read_csv(\"/content/herremans_hit_1030training.csv\")\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-24 06:14:48--  https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030training.csv\n",
            "Resolving dorax.s3.ap-south-1.amazonaws.com (dorax.s3.ap-south-1.amazonaws.com)... 52.219.66.103\n",
            "Connecting to dorax.s3.ap-south-1.amazonaws.com (dorax.s3.ap-south-1.amazonaws.com)|52.219.66.103|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 147372 (144K) [text/csv]\n",
            "Saving to: â€˜herremans_hit_1030training.csv.1â€™\n",
            "\n",
            "herremans_hit_1030t 100%[===================>] 143.92K   206KB/s    in 0.7s    \n",
            "\n",
            "2022-06-24 06:14:49 (206 KB/s) - â€˜herremans_hit_1030training.csv.1â€™ saved [147372/147372]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_y = torch.tensor(data[\"Topclass1030\"].values).view(-1,1)\n",
        "data_x = torch.tensor(data.drop(\"Topclass1030\", 1).values)\n",
        "num_features = data_x.shape[1]\n",
        "print(num_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYIJy1uyTXzJ",
        "outputId": "50d7ab52-6f90-4e90-9b53-762efe58ced9"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "  # input_size: Dimensionality of input feature vector.\n",
        "  # num_classes: The number of classes in the classification problem.\n",
        "  def __init__(self, input_size, num_classes):\n",
        "    # Always call the superclass (nn.Module) constructor first!\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    # Set up the linear transform\n",
        "    self.linear = nn.Linear(input_size, num_classes)\n",
        "    # I do not yet include the sigmoid activation after the linear \n",
        "    # layer because our loss function will include this as you will see later\n",
        "\n",
        "  # Forward's sole argument is the input.\n",
        "  # input is of shape (batch_size, input_size)\n",
        "  def forward(self, x):\n",
        "    # Apply the linear transform.\n",
        "    # out is of shape (batch_size, num_classes). \n",
        "    out = self.linear(x)\n",
        "    out = torch.sigmoid(out)\n",
        "    # Softmax the out tensor to get a log-probability distribution\n",
        "    # over classes for each example.\n",
        "    return out"
      ],
      "metadata": {
        "id": "m9iS8_bOU_OT"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logreg_model = LogisticRegression(num_features, 1)\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# print(device)\n",
        "# logreg_model = logreg_model.to(device)"
      ],
      "metadata": {
        "id": "p82ooub3V0fl"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_rate = 0.001\n",
        "\n",
        "# data_x_gpu = data_x.to(device)\n",
        "# data_y_gpu = data_y.to(device)\n",
        "\n",
        "\n",
        "loss_function = nn.BCELoss() \n",
        "# SGD: stochastic gradient descent is used to train/fit the model\n",
        "optimizer = torch.optim.SGD(logreg_model.parameters(), lr=lr_rate)"
      ],
      "metadata": {
        "id": "vXxaWEIvXyB5"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "step = data_x.shape[0]\n",
        "\n",
        "for i in range(epochs):\n",
        "  for j in range(step):\n",
        "    # randomly sample from all the examples\n",
        "    index = np.random.randint(data_x.shape[0])\n",
        "    x_var = torch.tensor(data_x[index]).float()\n",
        "    y_var = torch.tensor(data_y[index]).float()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    y_hat = logreg_model(x_var)\n",
        "\n",
        "    loss = loss_function(y_hat, y_var) \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  if i % 10 == 0:\n",
        "    print(f\"epoch {i} complete, loss = {loss.data.numpy()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfWJV7b5alks",
        "outputId": "1c83b57e-fd56-43a7-e2f2-7b9e1f997cc8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 complete, loss = 0.5311824083328247\n",
            "epoch 10 complete, loss = 1.346374750137329\n",
            "epoch 20 complete, loss = 0.6477197408676147\n",
            "epoch 30 complete, loss = 0.22680331766605377\n",
            "epoch 40 complete, loss = 0.27648574113845825\n",
            "epoch 50 complete, loss = 0.16359376907348633\n",
            "epoch 60 complete, loss = 1.5551060438156128\n",
            "epoch 70 complete, loss = 0.1125195249915123\n",
            "epoch 80 complete, loss = 0.21069541573524475\n",
            "epoch 90 complete, loss = 0.2937425673007965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw4yfGoGuChe"
      },
      "source": [
        "Run the below code to test the accuracy of your model on the training set: "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030test.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NseRCrWhdw-I",
        "outputId": "94dda0fd-0b6e-4acc-c150-01ec0335cb8f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-24 06:47:32--  https://dorax.s3.ap-south-1.amazonaws.com/herremans_hit_1030test.csv\n",
            "Resolving dorax.s3.ap-south-1.amazonaws.com (dorax.s3.ap-south-1.amazonaws.com)... 52.219.158.202\n",
            "Connecting to dorax.s3.ap-south-1.amazonaws.com (dorax.s3.ap-south-1.amazonaws.com)|52.219.158.202|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 36712 (36K) [text/csv]\n",
            "Saving to: â€˜herremans_hit_1030test.csvâ€™\n",
            "\n",
            "herremans_hit_1030t 100%[===================>]  35.85K   155KB/s    in 0.2s    \n",
            "\n",
            "2022-06-24 06:47:33 (155 KB/s) - â€˜herremans_hit_1030test.csvâ€™ saved [36712/36712]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L88WmKtMt5gH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "862353a3-5a06-4bef-9594-7687330758ca"
      },
      "source": [
        "# TP import pandas as pd \n",
        "\n",
        "\n",
        "test = pd.read_csv('/content/herremans_hit_1030test.csv')\n",
        "labels = test.iloc[:,-1]\n",
        "test = test.drop('Topclass1030', axis=1)\n",
        "testdata = torch.Tensor(test.values)\n",
        "testlabels = torch.Tensor(labels.values).view(-1,1)\n",
        "\n",
        "TP = 0\n",
        "TN = 0\n",
        "FN = 0\n",
        "FP = 0\n",
        "\n",
        "for i in range(0, testdata.size()[0]): \n",
        "  # print(testdata[i].size())\n",
        "  Xtest = torch.Tensor(testdata[i])\n",
        "  y_hat = logreg_model(Xtest)\n",
        "  \n",
        "  if y_hat > 0.5:\n",
        "    prediction = 1\n",
        "  else: \n",
        "    prediction = 0\n",
        "\n",
        "  if (prediction == testlabels[i]):\n",
        "    if (prediction == 1):\n",
        "      TP += 1\n",
        "    else: \n",
        "      TN += 1\n",
        "\n",
        "  else:\n",
        "    if (prediction == 1):\n",
        "      FP += 1\n",
        "    else: \n",
        "      FN += 1\n",
        "\n",
        "print(\"True Positives: {0}, True Negatives: {1}\".format(TP, TN))\n",
        "print(\"False Positives: {0}, False Negatives: {1}\".format(FP, FN))\n",
        "rate = TP/(FN+TP)\n",
        "print(\"Class specific accuracy of correctly predicting a hit song is {0}\".format(rate))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Positives: 43, True Negatives: 15\n",
            "False Positives: 14, False Negatives: 7\n",
            "Class specific accuracy of correctly predicting a hit song is 0.86\n"
          ]
        }
      ]
    }
  ]
}